{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Baseline Model: TF-IDF + Logistic Regression\n",
    "\n",
    "**Goal:** Build our first sentiment classification model.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Load the cleaned data\n",
    "2. Split into training and test sets\n",
    "3. Convert text to numbers using TF-IDF\n",
    "4. Train a Logistic Regression model\n",
    "5. Evaluate how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['clean_review', 'sentiment', 'source', 'review_length']\n",
      "Shape: (238638, 4)\n",
      "First row of clean_review: one of the other reviewers has mentioned that afte\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\ogaga\\OneDrive\\Desktop\\Everything AI and ML\\sentiment-analysis-project\\data\\processed\\combined_reviews_clean.csv')\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"First row of clean_review:\", df['clean_review'].iloc[0][:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup\n",
    "\n",
    "**YOUR TASK:** Import the libraries.\n",
    "\n",
    "You need:\n",
    "- `pandas` (as pd)\n",
    "- `from sklearn.model_selection import train_test_split` — splits data\n",
    "- `from sklearn.feature_extraction.text import TfidfVectorizer` — converts text to numbers\n",
    "- `from sklearn.linear_model import LogisticRegression` — our model\n",
    "- `from sklearn.metrics import accuracy_score, classification_report, confusion_matrix` — evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Import all libraries listed above\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split     \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Load the Cleaned Data\n",
    "\n",
    "**YOUR TASK:** Load the combined cleaned dataset we saved in Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Part 2: Load the cleaned data\ndf = pd.read_csv(r'C:\\Users\\ogaga\\OneDrive\\Desktop\\Everything AI and ML\\sentiment-analysis-project\\data\\processed\\combined_reviews_clean.csv')\ndf = df.dropna(subset=['clean_review', 'sentiment'])\ndf = df[df['clean_review'].str.strip() != '']\n\nprint(\"Shape of the dataset:\", df.shape)\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Prepare the Data\n",
    "\n",
    "We need to separate our data into:\n",
    "- **X** = the input (review text) — what the model reads\n",
    "- **y** = the label (positive/negative) — what the model predicts\n",
    "\n",
    "**YOUR TASK:** Create X and y from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Part 3: Prepare the data\nX = df['clean_review']\ny = df['sentiment']\n\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Train/Test Split\n",
    "\n",
    "Split the data: 80% for training, 20% for testing.\n",
    "\n",
    "**NEW CONCEPT: `train_test_split()`**\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "- `test_size=0.2` → 20% goes to test, 80% to train\n",
    "- `random_state=42` → makes the split reproducible (same split every time you run it)\n",
    "\n",
    "**YOUR TASK:** Write the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 190910 reviews\n",
      "Test set: 47728 reviews\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_train.shape[0]} reviews\")\n",
    "print(f\"Test set: {X_test.shape[0]} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Convert Text to Numbers (TF-IDF)\n",
    "\n",
    "The model can't read text. TF-IDF converts each review into a vector of numbers.\n",
    "\n",
    "**NEW CONCEPT: `TfidfVectorizer`**\n",
    "\n",
    "```python\n",
    "tfidf = TfidfVectorizer(max_features=50000)\n",
    "```\n",
    "\n",
    "- `max_features=50000` → only keep the 50,000 most important words\n",
    "\n",
    "**Important:** We `.fit_transform()` on training data and `.transform()` on test data.\n",
    "\n",
    "Why? The model should only learn vocabulary from training data. If it sees test data vocabulary during training, that's **data leakage** — like seeing exam answers before the test.\n",
    "\n",
    "**YOUR TASK:** Create the TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Fit on training data AND transform it\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# YOUR CODE: X_train_tfidf = tfidf.fit_transform(???)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 3: Only transform test data (don't fit again!)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# YOUR CODE: X_test_tfidf = tfidf.transform(???)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_test_tfidf \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=50000)\n",
    "\n",
    "# Step 2: Fit on training data AND transform it\n",
    "# YOUR CODE: X_train_tfidf = tfidf.fit_transform(???)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Step 3: Only transform test data (don't fit again!)\n",
    "# YOUR CODE: X_test_tfidf = tfidf.transform(???)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF training matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"TF-IDF test matrix shape: {X_test_tfidf.shape}\")\n",
    "print(f\"\\nThis means: {X_train_tfidf.shape[0]} reviews, each represented by {X_train_tfidf.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Train the Model\n",
    "\n",
    "Now we train Logistic Regression on the TF-IDF features.\n",
    "\n",
    "**YOUR TASK:** Create and train the model.\n",
    "\n",
    "```python\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "```\n",
    "\n",
    "- `max_iter=1000` → gives the model enough iterations to converge (find the best solution)\n",
    "- `.fit()` → this is where the actual learning happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Create and train the Logistic Regression model\n",
    "\n",
    "\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Make Predictions\n",
    "\n",
    "Use the trained model to predict sentiment on the **test set** (data it has never seen).\n",
    "\n",
    "**YOUR TASK:** Generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Use model.predict() on the test TF-IDF data\n",
    "# y_pred = model.predict(???)\n",
    "\n",
    "\n",
    "print(f\"Predictions made for {len(y_pred)} reviews\")\n",
    "print(f\"\\nFirst 10 predictions: {y_pred[:10]}\")\n",
    "print(f\"First 10 actual:      {y_test[:10].values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Evaluate the Model\n",
    "\n",
    "How well did our model do?\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Accuracy** — What % of predictions were correct?\n",
    "- **Precision** — When it said 'positive', how often was it right?\n",
    "- **Recall** — Of all actual positives, how many did it catch?\n",
    "- **F1 Score** — Balance between precision and recall\n",
    "\n",
    "**YOUR TASK:** Print the accuracy and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# YOUR CODE: accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"This means the model got {accuracy*100:.1f}% of predictions correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report — shows precision, recall, F1 for each class\n",
    "# YOUR CODE: print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix — shows where the model got confused\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['negative', 'positive'],\n",
    "            yticklabels=['negative', 'positive'])\n",
    "plt.title('Confusion Matrix — Logistic Regression Baseline', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/confusion_matrix_baseline.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow to read this:\")\n",
    "print(f\"  True Negatives (correct): {cm[0][0]}\")\n",
    "print(f\"  False Positives (wrong):  {cm[0][1]}\")\n",
    "print(f\"  False Negatives (wrong):  {cm[1][0]}\")\n",
    "print(f\"  True Positives (correct): {cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Test With Your Own Reviews\n",
    "\n",
    "Let's see if the model works on reviews you write yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own reviews!\n",
    "# Write any review and see what the model predicts\n",
    "\n",
    "my_reviews = [\n",
    "    \"This product is absolutely amazing, I love it!\",\n",
    "    \"Terrible experience, worst purchase I ever made.\",\n",
    "    \"It was okay, nothing special but not bad either.\",\n",
    "    \"The quality is outstanding and the price is fair.\",\n",
    "    \"Broke after two days. Total waste of money.\"\n",
    "]\n",
    "\n",
    "# Transform using the SAME tfidf vectorizer (important!)\n",
    "my_reviews_tfidf = tfidf.transform(my_reviews)\n",
    "\n",
    "# Predict\n",
    "my_predictions = model.predict(my_reviews_tfidf)\n",
    "\n",
    "# Show results\n",
    "print(\"=\" * 60)\n",
    "for review, pred in zip(my_reviews, my_predictions):\n",
    "    print(f\"Review:     {review}\")\n",
    "    print(f\"Prediction: {pred}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 10: Save the Model\n",
    "\n",
    "Save the trained model so we don't have to retrain it every time.\n",
    "\n",
    "**NEW CONCEPT: `joblib`**\n",
    "\n",
    "joblib saves Python objects (like our model) to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model and the TF-IDF vectorizer\n",
    "# We need BOTH to make predictions later\n",
    "joblib.dump(model, '../models/logistic_regression_baseline.pkl')\n",
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model saved to models/logistic_regression_baseline.pkl\")\n",
    "print(\"TF-IDF vectorizer saved to models/tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Fill this in:\n",
    "\n",
    "1. **Model:** Logistic Regression with TF-IDF features\n",
    "2. **Training set size:** _____ reviews\n",
    "3. **Test set size:** _____ reviews\n",
    "4. **Accuracy:** _____% \n",
    "5. **Best at predicting:** positive or negative?\n",
    "6. **Custom review test:** Did it get them right?\n",
    "\n",
    "### Questions to think about:\n",
    "- Is this accuracy good enough for a real product?\n",
    "- What types of reviews did it get wrong?\n",
    "- Could a more complex model do better?\n",
    "- What happens with neutral/sarcastic reviews?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}